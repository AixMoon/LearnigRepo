{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "colab": {
   "name": "task_2_main.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bgiq_D7pCIV"
   },
   "source": [
    "### Coursework coding instructions \n",
    "\n",
    "For the task you can choose to expand on baseline 1 or baseline 2 or add your own method. You can also expand on the pre-processing, feature extraction and data analysis\n",
    "\n",
    "#### Running your code:\n",
    "  - Your models should run automatically when running your colab file without further intervention\n",
    "  - For each task you should automatically output the performance of both models\n",
    "  - Your code should automatically download any libraries required\n",
    "\n",
    "#### Structure of your code:\n",
    "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
    "  - Otherwise there are no restrictions on what you can do in your code\n",
    "\n",
    "#### Documentation:\n",
    "  - You are expected to produce a .README section in this file summarising how you have approached both tasks\n",
    "\n",
    "#### Reproducibility:\n",
    "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
    "\n",
    "Good luck! We are really looking forward to seeing your reports and your model code!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ctZiGPdWpCJI"
   },
   "source": [
    "# You will need to download any word embeddings required for your code, e.g.:\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip\n",
    "\n",
    "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
    "\n",
    "#! pip install torch"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-26 15:23:30--  http://nlp.stanford.edu/data/glove.6B.zip\r\n",
      "Connecting to 127.0.0.1:7890... connected.\r\n",
      "Proxy request sent, awaiting response... 302 Found\r\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\r\n",
      "--2021-03-26 15:23:32--  https://nlp.stanford.edu/data/glove.6B.zip\r\n",
      "Connecting to 127.0.0.1:7890... connected.\r\n",
      "Proxy request sent, awaiting response... 301 Moved Permanently\r\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\r\n",
      "--2021-03-26 15:23:38--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\r\n",
      "Connecting to 127.0.0.1:7890... connected.\r\n",
      "Proxy request sent, awaiting response... 200 OK\r\n",
      "Length: 862182613 (822M) [application/zip]\r\n",
      "Saving to: ‘glove.6B.zip.2’\r\n",
      "\r\n",
      "glove.6B.zip.2        0%[                    ]   3.66M  1.11MB/s    eta 12m 43s^C\r\n",
      "Archive:  glove.6B.zip\r\n",
      "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/IPython/utils/_process_posix.py\u001B[0m in \u001B[0;36msystem\u001B[0;34m(self, cmd)\u001B[0m\n\u001B[1;32m    161\u001B[0m                 \u001B[0;31m# know whether we've finished (if we matched EOF) or not\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 162\u001B[0;31m                 \u001B[0mres_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mchild\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpect_list\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpatterns\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_timeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    163\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchild\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbefore\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mout_size\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'replace'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mend\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pexpect/spawnbase.py\u001B[0m in \u001B[0;36mexpect_list\u001B[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001B[0m\n\u001B[1;32m    371\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 372\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mexp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpect_loop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    373\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pexpect/expect.py\u001B[0m in \u001B[0;36mexpect_loop\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    168\u001B[0m                 \u001B[0;31m# Still have time left, so read more data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 169\u001B[0;31m                 \u001B[0mincoming\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspawn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_nonblocking\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspawn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmaxread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    170\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspawn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdelayafterread\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001B[0m in \u001B[0;36mread_nonblocking\u001B[0;34m(self, size, timeout)\u001B[0m\n\u001B[1;32m    499\u001B[0m         \u001B[0;31m# (possibly timeout=None), we call select() with a timeout.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 500\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    501\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspawn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_nonblocking\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001B[0m in \u001B[0;36mselect\u001B[0;34m(timeout)\u001B[0m\n\u001B[1;32m    449\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 450\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mselect_ignore_interrupts\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchild_fd\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    451\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pexpect/utils.py\u001B[0m in \u001B[0;36mselect_ignore_interrupts\u001B[0;34m(iwtd, owtd, ewtd, timeout)\u001B[0m\n\u001B[1;32m    142\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 143\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mselect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miwtd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mowtd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mewtd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    144\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mInterruptedError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-4a6797ebb6a2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'wget http://nlp.stanford.edu/data/glove.6B.zip'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'unzip glove.6B.zip'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel/zmqshell.py\u001B[0m in \u001B[0;36msystem_piped\u001B[0;34m(self, cmd)\u001B[0m\n\u001B[1;32m    633\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muser_ns\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'_exit_code'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    634\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 635\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muser_ns\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'_exit_code'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvar_expand\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcmd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdepth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    636\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    637\u001B[0m     \u001B[0;31m# Ensure new system_piped implementation is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/IPython/utils/_process_posix.py\u001B[0m in \u001B[0;36msystem\u001B[0;34m(self, cmd)\u001B[0m\n\u001B[1;32m    171\u001B[0m             \u001B[0;31m# (the character is known as ETX for 'End of Text', see\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m             \u001B[0;31m# curses.ascii.ETX).\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 173\u001B[0;31m             \u001B[0mchild\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msendline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    174\u001B[0m             \u001B[0;31m# Read and print any more output the program might produce on its\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m             \u001B[0;31m# way out.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001B[0m in \u001B[0;36msendline\u001B[0;34m(self, s)\u001B[0m\n\u001B[1;32m    576\u001B[0m         '''\n\u001B[1;32m    577\u001B[0m         \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_coerce_send_string\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 578\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinesep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    579\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_log_control\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, s)\u001B[0m\n\u001B[1;32m    567\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    568\u001B[0m         \u001B[0mb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_encoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfinal\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 569\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchild_fd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    570\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    571\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0msendline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOSError\u001B[0m: [Errno 5] Input/output error"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0iA-C2dcpCJN"
   },
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import torch.optim as optim\n",
    "import codecs\n",
    "import tqdm"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uWs9IykGpCJQ"
   },
   "source": [
    "# Setting random seed and device\n",
    "SEED = 1\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ITI-7C13pCJS"
   },
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('data/task-2/train.csv')\n",
    "test_df = pd.read_csv('data/task-2/dev.csv')"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dC4ZVEmBpCJT"
   },
   "source": [
    "# Number of epochs\n",
    "epochs = 20\n",
    "\n",
    "# Proportion of training data for train compared to dev\n",
    "train_proportion = 0.8\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3FGvU_UpCJU"
   },
   "source": [
    "#### Approach 1: Using pre-trained word representations (GLOVE)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u9mZ3V13pCJW"
   },
   "source": [
    "# We define our training loop\n",
    "def train(train_iter, dev_iter, model, number_epoch):\n",
    "    \"\"\"\n",
    "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Training model.\")\n",
    "\n",
    "    for epoch in range(1, number_epoch+1):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        epoch_correct = 0\n",
    "        no_observations = 0  # Observations used for training so far\n",
    "\n",
    "        for batch in train_iter:\n",
    "            feature, target = batch\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # for RNN:\n",
    "            model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            predictions = model(feature).squeeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            correct, __ = model_performance(np.argmax(predictions.detach().cpu().numpy(), axis=1), target.detach().cpu().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_correct += correct\n",
    "\n",
    "        valid_loss, valid_acc, __, __ = eval(dev_iter, model)\n",
    "\n",
    "        epoch_loss, epoch_acc = epoch_loss / no_observations, epoch_correct / no_observations\n",
    "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train Accuracy: {epoch_acc:.2f} | \\\n",
    "        Val. Loss: {valid_loss:.2f} | Val. Accuracy: {valid_acc:.2f} |')"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h4TIRKC0pCJZ"
   },
   "source": [
    "# We evaluate performance on our dev set\n",
    "def eval(data_iter, model):\n",
    "    \"\"\"\n",
    "    Evaluating model performance on the dev set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    pred_all = []\n",
    "    trg_all = []\n",
    "    no_observations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_iter:\n",
    "            feature, target = batch\n",
    "\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # for RNN:\n",
    "            model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            predictions = model(feature).squeeze(1)\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            # We get the mse\n",
    "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "            correct, __ = model_performance(np.argmax(pred, axis=1), trg)\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_correct += correct\n",
    "            pred_all.extend(pred)\n",
    "            trg_all.extend(trg)\n",
    "\n",
    "    return epoch_loss/no_observations, epoch_correct/no_observations, np.array(pred_all), np.array(trg_all)"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iI3iXWnMpCJb"
   },
   "source": [
    "# How we print the model performance\n",
    "def model_performance(output, target, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    correct_answers = (output == target)\n",
    "    correct = sum(correct_answers)\n",
    "    acc = np.true_divide(correct,len(output))\n",
    "\n",
    "    if print_output:\n",
    "        print(f'| Acc: {acc:.2f} ')\n",
    "\n",
    "    return correct, acc"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-opM9TDlpCJd"
   },
   "source": [
    "# To create our vocab\n",
    "def create_vocab(data):\n",
    "    \"\"\"\n",
    "    Creating a corpus of all the tokens used\n",
    "    \"\"\"\n",
    "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
    "\n",
    "    for sentence in data:\n",
    "\n",
    "        tokenized_sentence = []\n",
    "\n",
    "        for token in sentence.split(' '): # simplest split is\n",
    "\n",
    "            tokenized_sentence.append(token)\n",
    "\n",
    "        tokenized_corpus.append(tokenized_sentence)\n",
    "\n",
    "    # Create single list of all vocabulary\n",
    "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
    "\n",
    "    for sentence in tokenized_corpus:\n",
    "\n",
    "        for token in sentence:\n",
    "\n",
    "            if token not in vocabulary:\n",
    "\n",
    "                if True:\n",
    "                    vocabulary.append(token)\n",
    "\n",
    "    return vocabulary, tokenized_corpus"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1oHN7atmpCJi"
   },
   "source": [
    "# Used for collating our observations into minibatches:\n",
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    We add padding to our minibatches and create tensors for our model\n",
    "    '''\n",
    "\n",
    "    batch_labels = [l for f, l in batch]\n",
    "    batch_features = [f for f, l in batch]\n",
    "\n",
    "    batch_features_len = [len(f) for f, l in batch]\n",
    "\n",
    "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
    "\n",
    "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
    "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "\n",
    "    batch_labels = torch.LongTensor(batch_labels)\n",
    "\n",
    "    return seq_tensor, batch_labels\n",
    "\n",
    "# We create a Dataset so we can create minibatches\n",
    "class Task2Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, train_data, labels):\n",
    "        self.x_train = train_data\n",
    "        self.y_train = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.x_train[item], self.y_train[item]"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8C1uu91ZpCJm"
   },
   "source": [
    "\n",
    "class BiLSTM_classification(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
    "        super(BiLSTM_classification, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2label = nn.Linear(hidden_dim * 2, 3)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
    "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
    "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embedded = self.embedding(sentence)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
    "\n",
    "        out = self.hidden2label(lstm_out[-1])\n",
    "        return out"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3tvo0qlzpCJq",
    "outputId": "3f169f1e-b516-4639-ddb8-6d3442065d52",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Approach 1 code, using functions defined above:\n",
    "\n",
    "# We set our training data and test data\n",
    "training_data = train_df['original1']\n",
    "test_data = test_df['original1']\n",
    "\n",
    "##### Preproceccing the data\n",
    "train_df['original1']\n",
    "\n",
    "# Creating word vectors\n",
    "training_vocab, training_tokenized_corpus = create_vocab(training_data)\n",
    "test_vocab, test_tokenized_corpus = create_vocab(test_data)\n",
    "\n",
    "# Creating joint vocab from test and train:\n",
    "joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, test_data]))\n",
    "\n",
    "print(\"Vocab created.\")\n",
    "\n",
    "# We create representations for our tokens\n",
    "wvecs = [] # word vectors\n",
    "word2idx = [] # word2index\n",
    "idx2word = []\n",
    "\n",
    "# This is a large file, it will take a while to load in the memory!\n",
    "with codecs.open('glove.6B.100d.txt', 'r','utf-8') as f:\n",
    "  index = 1\n",
    "  for line in f.readlines():\n",
    "    # Ignore the first line - first line typically contains vocab, dimensionality\n",
    "    if len(line.strip().split()) > 3:\n",
    "      word = line.strip().split()[0]\n",
    "      if word in joint_vocab:\n",
    "          (word, vec) = (word,\n",
    "                     list(map(float,line.strip().split()[1:])))\n",
    "          wvecs.append(vec)\n",
    "          word2idx.append((word, index))\n",
    "          idx2word.append((index, word))\n",
    "          index += 1\n",
    "\n",
    "\n",
    "wvecs = np.array(wvecs)\n",
    "word2idx = dict(word2idx)\n",
    "idx2word = dict(idx2word)\n",
    "\n",
    "vectorized_seqs = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in training_tokenized_corpus]\n",
    "\n",
    "INPUT_DIM = len(word2idx)\n",
    "EMBEDDING_DIM = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = BiLSTM_classification(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\n",
    "print(\"Model initialised.\")\n",
    "\n",
    "model.to(device)\n",
    "# We provide the model with our embeddings\n",
    "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
    "\n",
    "feature = vectorized_seqs\n",
    "\n",
    "# 'feature' is a list of lists, each containing embedding IDs for word tokens\n",
    "train_and_dev = Task2Dataset(feature, train_df['label'])\n",
    "\n",
    "train_examples = round(len(train_and_dev)*train_proportion)\n",
    "dev_examples = len(train_and_dev) - train_examples\n",
    "\n",
    "train_dataset, dev_dataset = random_split(train_and_dev,\n",
    "                                           (train_examples,\n",
    "                                            dev_examples))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "\n",
    "print(\"Dataloaders created.\")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab created.\n",
      "Model initialised.\n",
      "Dataloaders created.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.46 | Train Accuracy: 0.73 |         Val. Loss: 2.51 | Val. Accuracy: 0.50 |\n",
      "| Epoch: 02 | Train Loss: 0.46 | Train Accuracy: 0.74 |         Val. Loss: 2.59 | Val. Accuracy: 0.48 |\n",
      "| Epoch: 03 | Train Loss: 0.47 | Train Accuracy: 0.73 |         Val. Loss: 2.58 | Val. Accuracy: 0.49 |\n",
      "| Epoch: 04 | Train Loss: 0.46 | Train Accuracy: 0.74 |         Val. Loss: 2.58 | Val. Accuracy: 0.48 |\n",
      "| Epoch: 05 | Train Loss: 0.46 | Train Accuracy: 0.73 |         Val. Loss: 2.52 | Val. Accuracy: 0.47 |\n",
      "| Epoch: 06 | Train Loss: 0.45 | Train Accuracy: 0.73 |         Val. Loss: 2.69 | Val. Accuracy: 0.48 |\n",
      "| Epoch: 07 | Train Loss: 0.45 | Train Accuracy: 0.74 |         Val. Loss: 2.72 | Val. Accuracy: 0.48 |\n",
      "| Epoch: 08 | Train Loss: 0.45 | Train Accuracy: 0.74 |         Val. Loss: 2.70 | Val. Accuracy: 0.47 |\n",
      "| Epoch: 09 | Train Loss: 0.45 | Train Accuracy: 0.74 |         Val. Loss: 2.71 | Val. Accuracy: 0.49 |\n",
      "| Epoch: 10 | Train Loss: 0.45 | Train Accuracy: 0.74 |         Val. Loss: 2.72 | Val. Accuracy: 0.47 |\n",
      "| Epoch: 11 | Train Loss: 0.45 | Train Accuracy: 0.73 |         Val. Loss: 2.68 | Val. Accuracy: 0.49 |\n",
      "| Epoch: 12 | Train Loss: 0.45 | Train Accuracy: 0.74 |         Val. Loss: 2.68 | Val. Accuracy: 0.48 |\n",
      "| Epoch: 13 | Train Loss: 0.44 | Train Accuracy: 0.74 |         Val. Loss: 2.82 | Val. Accuracy: 0.48 |\n",
      "| Epoch: 14 | Train Loss: 0.44 | Train Accuracy: 0.74 |         Val. Loss: 2.83 | Val. Accuracy: 0.49 |\n",
      "| Epoch: 15 | Train Loss: 0.44 | Train Accuracy: 0.74 |         Val. Loss: 2.83 | Val. Accuracy: 0.49 |\n",
      "| Epoch: 16 | Train Loss: 0.44 | Train Accuracy: 0.75 |         Val. Loss: 2.68 | Val. Accuracy: 0.50 |\n",
      "| Epoch: 17 | Train Loss: 0.45 | Train Accuracy: 0.74 |         Val. Loss: 2.74 | Val. Accuracy: 0.47 |\n",
      "| Epoch: 18 | Train Loss: 0.45 | Train Accuracy: 0.74 |         Val. Loss: 2.75 | Val. Accuracy: 0.47 |\n",
      "| Epoch: 19 | Train Loss: 0.44 | Train Accuracy: 0.74 |         Val. Loss: 2.82 | Val. Accuracy: 0.47 |\n",
      "| Epoch: 20 | Train Loss: 0.44 | Train Accuracy: 0.74 |         Val. Loss: 2.79 | Val. Accuracy: 0.49 |\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train(train_loader, dev_loader, model, epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-cb82e66ba81b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0ma\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdev_loader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataLoader' object has no attribute 'datasets'"
     ]
    }
   ],
   "source": [
    "a = dev_loader.dataset\n",
    "\n",
    "for batch in dev_loader:\n",
    "    feature, target = batch\n",
    "    feature, target = feature.to(device), target.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}